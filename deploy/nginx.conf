worker_processes 1;
daemon off;
events {
    worker_connections 1024;
}
http {
    proxy_cache_path /tmp/proxycache levels=1:2 keys_zone=public_channel_cache:10m max_size=10g
                    inactive=600m use_temp_path=off;
    include mime.types;
    sendfile on;
    gzip              on;
    gzip_http_version 1.0;
    gzip_proxied      any;
    gzip_min_length   500;
    client_max_body_size 1000M;
    gzip_disable      "MSIE [1-6]\.";
    gzip_types        text/plain text/xml text/css
                      text/comma-separated-values
                      text/javascript
                      application/x-javascript
                      application/atom+xml;

    # Proxy upstream to the gunicorn process
    upstream studio {
        server 127.0.0.1:8081;
        keepalive 5;
    }

    # Configuration for Nginx
    server {

        # Listen on port 8080
        # See https://nginx.org/en/docs/http/server_names.html for how this interacts with server_name
        listen 8080 default_server;

        # Explicitly set server_name to be empty.
        server_name "";

        # Settings to serve static files
        location /static/  {
            autoindex on;
            alias /app/contentworkshop_static/;
            expires 4h;
        }
        # Serve a static file (ex. favico)
        # outside /static directory
        location = /favico.ico  {
            root /app/favico.ico;
        }
        # Proxy connections to django
        location / {
            proxy_pass         http://studio;
            proxy_set_header   Host $host;
            proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_read_timeout 100s;
            proxy_redirect     off;
            proxy_cache        off;
        }

        # dynamically provisioned in the image's entrypoint script
        # see deploy/includes/content/*
        include /etc/nginx/includes/content.conf;

        # We cache the following expensive API endpoints.

        # cache the public channel endpoint.
        # the return value of this should be the same across all users,
        # and the return value should rarely change as well. This makes it
        # a candidate for long-running caches keyed simply by the URI.
        location /get_user_public_channels/ {
            proxy_cache public_channel_cache;
            proxy_pass  http://studio/get_user_public_channels/;

            # cache any 200 OK status code values for 10 minutes
            proxy_ignore_headers Cache-Control;
            proxy_cache_valid 200 10m;

            # ignore any get params
            proxy_cache_key $scheme$proxy_host$uri;
            # next two directives make nginx serve the cached value even when we're refreshing it
            proxy_cache_use_stale updating error;
            proxy_cache_background_update on;

            # proxy_cache_lock sends only 1 query to the server if there's a lot of them at once,
            # preventing stampedes
            proxy_cache_lock on;

            # show the cache status in a header
            add_header X-Cache-Status $upstream_cache_status;
        }
    }
}
